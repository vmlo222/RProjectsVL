---
title: "Project 1-Multivariate Methods"
author: "Vincent Locke"
date: "3/19/2018"
output: html_document
---
We need to set the directory and load the packages we will need.
```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = getwd())
```

```{r packages, include=FALSE}
pkgs <- c("scales","car","RColorBrewer",
          "scatterplot3d","plot3D","lattice",
          "dplyr","knitr") 
for (pkg in pkgs) {
  if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
  require(pkg, character.only = TRUE)
}
rm(pkgs, pkg)
```

This function was obtained from github  https://github.com/ChrKoenig/R_marginal_plot/blob/master/marginal_plot.R
```{r marginal_plot,echo=FALSE}
marginal_plot = function(x, y, group = NULL, data = NULL, lm_formula = y ~ x, bw = "nrd0", alpha = 1, plot_legend = T, ...){
  require(scales)
  ###############
  # Plots a scatterplot with marginal probability density functions for x and y. 
  # Data may be grouped or ungrouped. 
  # For each group, a linear fit is plotted. The model can be modified using the 'lm_formula' argument. Setting 'lm_formula' to NULL prevents plotting model fits.
  # The 'bw' argument specifies the bandwidth rule used for estimating probability density functions. See ?density for more information.
  # For large datasets, opacity may be decreased by setting alpha to a value between 0 and 1.
  # Additional graphical parameters are passed to the main plot, so you can customize axis labels, titles etc.
  ###############
  moreargs = eval(substitute(list(...)))
  
  # prepare consistent df
  if(missing(group)){
    if(missing(data)){
      if(length(x) != length(y)){stop("Length of arguments not equal")}
      data = data.frame(x = as.numeric(x), y = as.numeric(y))
    } else {
      data = data.frame(x = as.numeric(data[,deparse(substitute(x))]), 
                        y = as.numeric(data[,deparse(substitute(y))]))
    }
    if(sum(!complete.cases(data)) > 0){
      warning(sprintf("Removed %i rows with missing data", sum(!complete.cases(data))))
      data = data[complete.cases(data),]
    }
    group_colors = "black"
  } else {
    if(missing(data)){
      if(length(x) != length(y) | length(x) != length(group)){stop("Length of arguments not equal")}
      data = data.frame(x = as.numeric(x), y = as.numeric(y), group = as.factor(group))
    } else {
      data = data.frame(x = as.numeric(data[,deparse(substitute(x))]), 
                        y = as.numeric(data[,deparse(substitute(y))]),
                        group = as.factor(data[,deparse(substitute(group))]))
    }
    if(sum(!complete.cases(data)) > 0){
      warning(sprintf("Removed %i rows with missing data", sum(!complete.cases(data))))
      data = data[complete.cases(data),]
    }
    data = subset(data, group %in% names(which(table(data$group) > 5)))
    data$group = droplevels(data$group)
    group_colors = rainbow(length(unique(data$group)))
  } 
  
  # log-transform data (this is need for correct plotting of density functions)
  if(!is.null(moreargs$log)){
    if(!moreargs$log %in% c("y", "x", "yx", "xy")){
      warning("Ignoring invalid 'log' argument. Use 'y', 'x', 'yx' or 'xy.")
    } else {
      data = data[apply(data[unlist(strsplit(moreargs$log, ""))], 1, function(x) !any(x <= 0)), ]
      data[,unlist(strsplit(moreargs$log, ""))] = log10(data[,unlist(strsplit(moreargs$log, ""))])
    }
    moreargs$log = NULL # remove to prevent double logarithm when plotting
  }
  
  # Catch unwanted user inputs
  if(!is.null(moreargs$col)){moreargs$col = NULL}
  if(!is.null(moreargs$type)){moreargs$type = "p"}
  
  # get some default plotting arguments
  if(is.null(moreargs$xlim)){moreargs$xlim = range(data$x)} 
  if(is.null(moreargs$ylim)){moreargs$ylim = range(data$y)}
  if(is.null(moreargs$xlab)){moreargs$xlab = deparse(substitute(x))}
  if(is.null(moreargs$ylab)){moreargs$ylab = deparse(substitute(y))}
  if(is.null(moreargs$las)){moreargs$las = 1} 
  
  # plotting
  tryCatch(expr = {
    ifelse(!is.null(data$group), data_split <- split(data, data$group), data_split <- list(data))
    orig_par = par(no.readonly = T)
    par(mar = c(0.25,5,1,0))
    layout(matrix(1:4, nrow = 2, byrow = T), widths = c(10,3), heights = c(3,10))
    
    # upper density plot
    plot(NULL, type = "n", xlim = moreargs$xlim, ylab = "density",
         ylim = c(0, max(sapply(data_split, function(group_set) max(density(group_set$x, bw = bw)$y)))), main = NA, axes = F)
    axis(2, las = 1)
    mapply(function(group_set, group_color){lines(density(group_set$x, bw = bw), col = group_color, lwd = 2)}, data_split, group_colors)
    
    # legend
    par(mar = c(0.25,0.25,0,0))
    plot.new()
    if(!missing(group) & plot_legend){
      legend("center", levels(data$group), fill = group_colors, border = group_colors, bty = "n", title = deparse(substitute(group)), title.adj = 0.1)
    }
    
    # main plot
    par(mar = c(4,5,0,0))
    if(missing(group)){
      do.call(plot, c(list(x = quote(data$x), y = quote(data$y), col = quote(scales::alpha("black", alpha))), moreargs))
    } else {
      do.call(plot, c(list(x = quote(data$x), y = quote(data$y), col = quote(scales::alpha(group_colors[data$group], alpha))), moreargs))
    }
    axis(3, labels = F, tck = 0.01)
    axis(4, labels = F, tck = 0.01)
    box()
    
    if(!is.null(lm_formula)){
      mapply(function(group_set, group_color){
        lm_tmp = lm(lm_formula, data = group_set)
        x_coords = seq(min(group_set$x), max(group_set$x), length.out = 100)
        y_coords = predict(lm_tmp, newdata = data.frame(x = x_coords))
        lines(x = x_coords, y = y_coords, col = group_color, lwd = 2.5)
      }, data_split, rgb(t(ceiling(col2rgb(group_colors)*0.8)), maxColorValue = 255))
    }
    
    # right density plot
    par(mar = c(4,0.25,0,1))
    plot(NULL, type = "n", ylim = moreargs$ylim, xlim = c(0, max(sapply(data_split, function(group_set) max(density(group_set$y, bw = bw)$y)))), main = NA, axes = F, xlab = "density")
    mapply(function(group_set, group_color){lines(x = density(group_set$y, bw = bw)$y, y = density(group_set$y, bw = bw)$x, col = group_color, lwd = 2)}, data_split, group_colors)
    axis(1)
  }, finally = {
    par(orig_par)
  })
}
```

Load Bank Dataset
```{r Banking Data, echo=FALSE}
df.1<-read.table("~/Documents/GitHub/RProjectsVL/Data/P1-4.DAT",
                 col.names = c("Sales","Profits","Assets"))
```

Create a marginal plot comparing sales vs profits
```{r First Plot, echo=FALSE}
marginal_plot(x=df.1$Sales,y=df.1$Profits,
              xlab="Sales",ylab="Profits")
```

This plot shows that there is positive correlation between Sales and Profits with
somewhat of a linear relationship, but it can also be said that due to the small sample size this could be misleading.

Create a second marginal plot comparing profits vs assets
```{r Second Plot, echo=FALSE}
marginal_plot(x=df.1$Profits,y=df.1$Assets,
              xlab="Profits",ylab="Assets")
```

In this second marginal plot, we can actually see negative correlation between Profits and Assets.

Create a third marginal plot comparing sales vs assets
```{r Third Plot, echo=FALSE}
marginal_plot(x=df.1$Sales,y=df.1$Assets,
              xlab="Sales",ylab="Assets")
```

In this third marginal plot, similar to the second plot we see negative correlation between Sales and Assets as well.

Load the Radiotherapy Dataset
```{r Radiotherapy Data, echo=FALSE}
df.2<-read.table("~/Documents/GitHub/RProjectsVL/Data/T1-7.DAT",
                 col.names = c("Symptoms","Activity","Sleep","Food",
                               "Appetite","Skin"))
```

Create a marginal plot comparing the amount of activity vs amount of sleep
```{r Fourth Plot, echo=FALSE}
marginal_plot(x=df.2$Activity,y=df.2$Sleep,xlab="Amount of Activity",ylab="Amount of Sleep")
```

In this marginal plot, there is positive correlation between the amount of activity and the amount of sleep, but we can also see the presence of possible outliers that are shown in the top left corner.

Load the National Track Records for Women Dataset
```{r Womens Track Data, echo=FALSE}
df.3<-read.table("~/Documents/GitHub/RProjectsVL/Data/T1-9.dat",header = FALSE,
                 col.names = c("Country", "s100", "s200", "s400","m800","m1500","m3000","Marathon"))
```

Summary of Track Data
```{r summary,echo=FALSE}
summary(df.3)
```

Lets convert the country variable to character format and use this as 
our row name.
```{r,echo=FALSE }
df.3$Country<-as.character(df.3$Country)
df.a= df.3[, -1]
```

Mean of the variables
```{r,echo=FALSE }
X<-apply(df.a,2,mean)
X
```

Variance of the variables
```{r,echo=FALSE}
S<-var(df.a)
S
```

Correlation of the variables
```{r,echo=FALSE}
R<-cor(df.a)
R
```

The results show that there is positive correlation between the groups with the largest coming from races that are similar.

Lets convert the distance from Meters to Meters Per Second
```{r,echo=FALSE }
df.b<-df.a
df.b[,1]<-100/df.b[, 1]
df.b[,2]<-200/df.b[, 2]
df.b[,3]<-400/df.b[, 3]
df.b[,4:7]<-60*df.b[, 4:7]
df.b[,4]<-800/df.b[, 4]
df.b[,5]<-1500/df.b[, 5]
df.b[,6]<-3000/df.b[, 6]
df.b[,7]<-42195/df.b[, 7]
```

Mean of the variables
```{r,echo=FALSE }
X2<-apply(df.b,2,mean)
X2
```

Variance of the variables
```{r,echo=FALSE }
S2<-var(df.b)
S2
```

Correlation of the variables
```{r,echo=FALSE }
R2<-cor(df.b)
R2
```

The results are similar to our initial review of the mean, variance, and correlation. There's positive correlation between the groups with emphasis on the races with similar distances.

Load the Bankruptcy Dataset
```{r Bankruptcy Data, echo=FALSE}
df.4<-read.table("~/Documents/GitHub/RProjectsVL/Data/T11-4.DAT",header = FALSE,
                 col.names = c("X1CashFlow/TotalDebt","X2NetIncome/TotalAssets",  "X3CurrentAssets/CurrentLiabilites","X4CurrentAssets/NetSales","Population"))
```

Lets create a 3D scatter plot comparing bankruptcy vs nonbankruptcy banks
```{r scatterplot3d, echo=FALSE}
scatterplot3d(x=df.4$X3CurrentAssets.CurrentLiabilites,y=df.4$X1CashFlow.TotalDebt,z=df.4$X2NetIncome.TotalAssets,xlab = "CurrentAssets/CurrentLiabilites",
              ylab="CashFlow/TotalDebt",zlab="NetIncome/TotalAssets",color=par("col"),main="3D Scatterplot X2 X3 X1")
```

The 3D scatter plot suggests there could be some outliers towards the top right and the plot also looks like a cigar but bent towards the top, which is a good sign.

Now lets rearrange the Bankruptcy Dataset and change the d variable to numeric and the e variable to a factor
```{r rearranged bankruptcy data, echo=FALSE}
df.5<-data.frame(a=df.4$X3CurrentAssets.CurrentLiabilites,b=df.4$X1CashFlow.TotalDebt,c=df.4$X2NetIncome.TotalAssets,d=df.4$X4CurrentAssets.NetSales,e=df.4$Population)
```

```{r,echo=FALSE}
df.5$d<-as.numeric(df.5$d)
df.5$e<-as.factor(df.5$e)
```

Lets create a second 3D scatter plot showing bankruptcy and nonbankruptcy
```{r second scatterplot3d, echo=FALSE}
df.plot<-scatterplot3d(df.5[df.5$e=="1",],box=FALSE, pch=16,xlab="NetIncome/TotalAssets", ylab="CurrentAssets/CurrentLiabilites",zlab="CashFlow/TotalDebt",zlim=c(-0.5,1),
                       type="h", main="3D Scatterplot X2 X3 X1",
                       xlim = c(0,4),ylim = c(-0.5,1),highlight.3d=TRUE)
df.plot$points3d(df.5[df.5$e=="0",],col="red",type="h",pch=16)
legend("topright",legend=c("Non Bankruptcy","Bankruptcy"),col = c("black","red"),lty = 1,box.lty=0,pch=19)
```

The 3d scatter plot shows that there probably is an outlier for a bankrupted bank that shows up in the non-bankrupted banks.

Load the Public Utility Company Dataset
```{r Utility Data, echo=FALSE}
df.6<-read.table("~/Documents/GitHub/RProjectsVL/Data/T12-4.DAT",header = FALSE,
                 col.names=c("X1FixedChargeRatio","X2RateofReturnonCapital","X3CostPerKWcp","X4AnnualLoadFactor","X5PeakDemandGrowth","X6Sales","X7PercentNuclear","X8FuelCost","Company"))
```

Lets create a star chart
```{r starchart, echo=FALSE}
par(mfrow=c(2,2))
stars(df.6[,1:3],locations=c(0,0),key.loc=c(0,0),main="Group 1")
stars(df.6[,4:6],locations=c(0,0),key.loc=c(0,0),main="Group 2")
stars(df.6[,5:8],locations=c(0,0),key.loc=c(0,0),main="Group 3")
stars(df.6[,2:5],locations=c(0,0),key.loc=c(0,0),main="Group 4")
```

```{r,echo=FALSE }
dev.off()
```

Load the National Park Dataset Dataset
```{r Park Data, echo=FALSE}
df.7<-read.table("~/Documents/GitHub/RProjectsVL/Data/T1-11.dat",header = FALSE,
                 col.names = c("Size","Visitors"))
```

We need to create a new variable that will represent the parks
```{r new variable, echo=FALSE}
df.7$Park<-factor(rep(1:length(df.7$Size)))
```

National Parks
Arcadia          1
Bruce Canyon     2
Cuyahoga Valley  3
Everglades       4
Grand Canyon     5
Grand Teton      6
Great Smokey     7
Hot Springs      8
Olympic          9
Mount Rainier    10
Rocky Mountain   11
Shenandoah       12
Yellowstone      13
Yosemite         14
Zion             15

Create a scatter plot comparing size vs visitors
```{r Fifth Plot, echo=FALSE}
plot(x=df.7$Visitors,y=df.7$Size, main="Scatter Plot of X and Y",xlab="Number of visitors(in millions)",ylab="Size (in Acres)")
abline(lm(Size~Visitors,data=df.7),col="blue",lwd=3, lty=3)
```

If we take a look at the plot, we can clearly see that there is an outlier that is effecting model. 

To figure our which park is the outlier, lets take a look at the data.
```{r,echo=FALSE }
head(df.7,n=15)
```

Comparing the dataset to the scatter plot, we see that park 7 or The Great Smokey National Park is the outlier.

Before we do anything, lets check the correlation between Visitors and Size.
```{r,echo=FALSE }
cor(x=df.7$Visitors,y=df.7$Size)
```

It comes out at 0.1725274, which isnt the bet. So lets remove The Great Smokey National Park and plot the data and rerun the cor() to see if it improves correlation between the two.

First remove The Great Smokey National Park from the data.
```{r, echo=FALSE}
df.7<-df.7[-7,]
```

Now lets re-plot the scatter plot
```{r Sixth Plot, echo=FALSE}
plot(x=df.7$Visitors,y=df.7$Size, main="Updated Scatter Plot of X and Y",xlab="Number of visitors(in millions)",ylab="Size (in Acres)")
abline(lm(Size~Visitors,data=df.7),col="blue",lwd=3, lty=3)
```

It definitly improves the scatter plot so now lets also check correlation between the two again.
```{r,echo=FALSE }
cor(x=df.7$Visitors,y=df.7$Size)
```

The correlation coefficient is 0.3907829, which is definitly an improvement.
